---
title: 'AI and Theory Building'
date: '2025-06-12'
tags: ['Software', 'AI', 'Theory']
draft: false
summary: 'This post examines the idea that programming is less about code and more about the internal theory developers construct—a human practice of meaning-making that AI has yet to grasp, as articulated by Peter Naur.'
---

_Originally published on my [LinkedIn](https://www.linkedin.com/posts/sachin-tyagi_over-the-past-year-or-so-there-has-been-activity-7337525866966462464-u0eR)._

Over the past year or so, there has been widespread concern in tech circles about AI replacing software jobs. Those with a more optimistic view of software engineering's future emphasise that the field involves more than just writing code. That while AI's pattern recognition capabilities excel at generating certain artefacts, there's a certain “je ne sais quoi” in the craft of producing software that pattern recognisers trained on text alone cannot capture. This “irreducible something" often remains unnamed, and I've been trying to identify it.

The best candidate I've found is Peter Naur's conception of “Programming as Theory Building”. In that essay, Naur argued that none of the textual artefacts programmers produce truly captures programming's essence.

Rather, Naur contends that programming's essence lies in the theory programmers build in their minds about the system - a mental model encompassing how the program works, how it corresponds to the real world entities and models their relationships, how its components interact, what assumptions hold, and how it might evolve over time. The code is merely a secondary manifestation of this internal theory. As he puts it, programming isn't just about producing programs, but about building and possessing a theory of the program and the corresponding phenomena in the real world. This theory is lived knowledge - embodied in the individuals or teams who develop and maintain the software - and cannot be fully captured in documentation, diagrams, or even the source code.

He even goes so far as to distinguish between an intellectual exercise (essential to any theory building) and an exercise in intelligence (necessary for problem solving).

I think this is the best candidate for that “irreducible something” - the tacit knowledge and active engagement with a living system - that AI currently lacks. Naur's framing suggests that programming then isn't about the any final product but about a practice, a way of thinking, an ongoing negotiation with complexity, if you will.

(P.S. In a separate collection of essays, “The Mythical Man-Month”, Brooks places a similar emphasis on the importance of “conceptual integrity” while creating software.)
